<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <title>2D Hand Overlay with Audio</title>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: #000;
      font-family: 'Inter', sans-serif;
      color: white;
      text-align: center;
      touch-action: none;
    }

    #video-background {
      position: fixed;
      top: 0; left: 0;
      width: 100%; height: 100%;
      object-fit: cover;
      z-index: -1;
    }

    #overlay-canvas {
      position: fixed;
      top: 0; left: 0;
      width: 100%; height: 100%;
      pointer-events: none;
    }

    .overlay-image {
      position: fixed;
      width: 28vw;
      height: auto;
      max-height: 25vh;
      object-fit: contain;
      opacity: 0;
      transition: opacity 0.6s ease-in-out;
      transform: translate(-50%, -50%);
      will-change: opacity, transform;
    }
    .overlay-image.visible { opacity: 1; }

    #status-message {
      position: fixed;
      top: 8px; left: 50%;
      transform: translateX(-50%);
      background: rgba(0,0,0,0.6);
      padding: 6px 14px;
      border-radius: 8px;
      font-size: clamp(14px, 2vw, 18px);
      white-space: nowrap;
    }

    #category-buttons {
      position: fixed;
      bottom: 10px; left: 50%;
      transform: translateX(-50%);
      display: flex; gap: 8px;
      background: rgba(0,0,0,0.5);
      padding: 6px 10px;
      border-radius: 10px;
      flex-wrap: wrap;
      justify-content: center;
      max-width: 95vw;
      z-index: 50;
    }

    .category-button {
      background: rgba(255,255,255,0.15);
      border: none;
      padding: 8px;
      border-radius: 10px;
      font-size: clamp(20px, 8vw, 28px);
      cursor: pointer;
      transition: transform 0.2s, background-color 0.2s;
      min-width: 44px; min-height: 44px;
    }
    .category-button:active {
      background: rgba(255,255,255,0.35);
      transform: scale(1.05);
    }

    .all-emojis-grid {
      display: grid;
      grid-template-columns: repeat(2, 1fr);
      gap: 1px;
      font-size: 0.8em;
    }
  </style>
</head>
<body>
  <div id="status-message">Initializing camera...</div>
  <video id="video-background" autoplay playsinline muted></video>
  <canvas id="overlay-canvas"></canvas>

  <div id="category-buttons">
    <button class="category-button" onclick="setGifCategory('farm')">ğŸ„</button>
    <button class="category-button" onclick="setGifCategory('dino')">ğŸ¦–</button>
    <button class="category-button" onclick="setGifCategory('wheel')">ğŸ›</button>
    <button class="category-button" onclick="setGifCategory('zoo')">ğŸ¦</button>
    <button class="category-button" onclick="setGifCategory('music')">ğŸµ</button>
    <button class="category-button" onclick="setGifCategory('all')">
      <div class="all-emojis-grid"><span>ğŸ„</span><span>ğŸ¦–</span><span>ğŸ›</span><span>ğŸ¦</span><span>ğŸµ</span></div>
    </button>
  </div>

  <script type="module">
    import { HandLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";

    const video = document.getElementById("video-background");
    const statusMessage = document.getElementById("status-message");
    const canvas = document.getElementById("overlay-canvas");
    const ctx = canvas.getContext("2d");

    navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } })
      .then(stream => {
        video.srcObject = stream;
        statusMessage.textContent = "Loading hand model...";
      })
      .catch(err => {
        console.error("Webcam error:", err);
        statusMessage.textContent = "Enable camera permissions.";
      });

    function resizeCanvas() {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
    }
    video.addEventListener('loadedmetadata', resizeCanvas);
    window.addEventListener('resize', resizeCanvas);

    const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
    const handLandmarker = await HandLandmarker.createFromOptions(vision, {
      baseOptions: { modelAssetPath: "https://storage.googleapis.com/mediapipe-assets/hand_landmarker.task" },
      runningMode: "VIDEO",
      numHands: 1
    });

    // === AUDIO SYSTEM ===
    const synth = window.speechSynthesis;
    let currentAudio = null;
    let currentlyCollidingFileName = null;
    let isSpeaking = false;
    let sfxMap = {};

    function getFileName(url) {
      const parts = url.split('/');
      return parts.pop().split('.')[0].replace(/[0-9]/g, '').replace(/[^a-zA-Z]/g, '');
    }

    function speakAndPlay(fileName) {
      if (isSpeaking) return;
      isSpeaking = true;

      if (currentAudio) {
        currentAudio.pause();
        currentAudio = null;
      }

      const utterance = new SpeechSynthesisUtterance(fileName);
      utterance.lang = 'en-US';
      utterance.onend = () => {
        const sfxUrl = sfxMap[fileName];
        if (sfxUrl) {
          currentAudio = new Audio(sfxUrl);
          currentAudio.loop = true;
          currentAudio.play().catch(e => console.error("Audio failed:", e));
        }
        isSpeaking = false;
      };
      synth.speak(utterance);
    }

    // === HAND LOOP ===
    let lastVideoTime = -1;
    function animate() {
      requestAnimationFrame(animate);
      if (!video.videoWidth) return;

      const nowInMs = performance.now();
      if (video.currentTime === lastVideoTime) return;
      lastVideoTime = video.currentTime;

      ctx.clearRect(0, 0, canvas.width, canvas.height);

      const results = handLandmarker.detectForVideo(video, nowInMs);
      let collisionDetected = false;

      if (results.landmarks.length > 0) {
        statusMessage.textContent = "Hand Detected";
        const tip = results.landmarks[0][8];
        ctx.fillStyle = 'cyan';
        ctx.beginPath();
        ctx.arc(tip.x * canvas.width, tip.y * canvas.height, 8, 0, 2 * Math.PI);
        ctx.fill();

        const screenX = tip.x * window.innerWidth;
        const screenY = tip.y * window.innerHeight;
        const activeImages = document.querySelectorAll('.overlay-image.visible');

        for (const img of activeImages) {
          const rect = img.getBoundingClientRect();
          if (screenX > rect.left && screenX < rect.right && screenY > rect.top && screenY < rect.bottom) {
            collisionDetected = true;
            const fileName = img.dataset.filename;
            if (currentlyCollidingFileName !== fileName) {
              currentlyCollidingFileName = fileName;
              speakAndPlay(fileName);
            }
            break;
          }
        }
      } else {
        statusMessage.textContent = "No Hand";
      }

      if (!collisionDetected) {
        if (currentAudio) {
          currentAudio.pause();
          currentAudio = null;
        }
        currentlyCollidingFileName = null;
        if (synth.speaking && !isSpeaking) synth.cancel();
      }
    }
    animate();

    // === IMAGE LOGIC ===
    let imageUrls = [], currentImageIndex = 0, imageInterval = null;
    const positions = [
      { top: '20%', left: '25%' }, { top: '20%', left: '75%' },
      { top: '55%', left: '25%' }, { top: '55%', left: '75%' },
      { top: '35%', left: '50%' }
    ];
    let occupied = new Set();

    function shuffle(arr) { return arr.sort(() => Math.random() - 0.5); }

    async function fetchFiles(folders, ext) {
      let urls = [];
      for (const folder of folders) {
        try {
          const res = await fetch(`https://api.github.com/repos/boobalootoo/BRAINFRESHEN/contents/GIFS/${folder}`);
          const data = await res.json();
          urls.push(...data.filter(f => f.name.endsWith(ext)).map(f => f.download_url));
        } catch(e) { console.warn("Fetch failed:", e); }
      }
      return urls;
    }

    function clearImages() {
      document.querySelectorAll('.overlay-image').forEach(img => img.remove());
      occupied.clear();
      currentImageIndex = 0;
    }

    window.setGifCategory = async function(category) {
      if (imageInterval) clearInterval(imageInterval);
      clearImages();

      let folders = [];
      if (category === 'all') folders = ['DINO','FARM','ZOO','WHEEL','MUSIC'];
      else folders = [category.toUpperCase()];

      imageUrls = shuffle(await fetchFiles(folders, '.gif'));
      if (!imageUrls.length) return;

      imageInterval = setInterval(showNextImage, 2500);
    };

    function showNextImage() {
      if (!imageUrls.length) return;
      const freePositions = positions.filter((_, i) => !occupied.has(i));
      if (!freePositions.length) return; // wait until a spot frees up

      const posIndex = positions.indexOf(freePositions[Math.floor(Math.random() * freePositions.length)]);
      const pos = positions[posIndex];
      occupied.add(posIndex);

      const url = imageUrls[currentImageIndex];
      const img = document.createElement('img');
      img.src = url;
      img.className = 'overlay-image';
      img.dataset.filename = getFileName(url);
      img.style.top = pos.top;
      img.style.left = pos.left;
      document.body.appendChild(img);

      setTimeout(() => img.classList.add('visible'), 50);
      setTimeout(() => { img.remove(); occupied.delete(posIndex); }, 8000);

      currentImageIndex = (currentImageIndex + 1) % imageUrls.length;
    }

    // === SFX LOADING ===
    Promise.all([
      fetchFiles(['SFX'], '.mp3'),
      fetchFiles(['SFX'], '.wav')
    ]).then(([mp3Urls, wavUrls]) => {
      [...mp3Urls, ...wavUrls].forEach(url => {
        sfxMap[getFileName(url)] = url;
      });
      setGifCategory('farm'); // default
    });
  </script>
</body>
</html>
